\section*{Abstract}
Ensemble methods can be used to combine multiple learners to form a single, stronger learner. Across a wide range of fields, from financial to medical applications, machine learning is often applied in situations where maximum robustness and accuracy play a crucial role. This paper gives an overview of two ensemble methods - boosting and bagging - and shows how these methods can be utilized. Various choices of voting, boosting, and bagging methods are covered. An additional focus is also put on the common Random Forests and AdaBoost methods. Finally, a guideline on when to use which ensemble method is provided to guide future decisions on which methods to choose.